import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import warnings
import collections
from typing import Dict, List, Tuple, Optional
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader

import flwr as fl
from flwr.common import (
    Parameters,
    FitRes,
    EvaluateRes,
    FitIns,
    EvaluateIns,
    NDArrays,
    GetParametersIns,
    GetParametersRes,
    Status,
    Code,
    ndarrays_to_parameters,
    parameters_to_ndarrays,
)
from flwr.server.strategy import FedAvg
from flwr.server.client_proxy import ClientProxy

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix)

print("="*80)
print(" "*10 + "FEDERATED LEARNING WITH FLOWER + PYTORCH")
print(" "*10 + "Heart Disease Prediction with Non-IID Data")
print("="*80)
print(f"\n‚úì PyTorch version:  {torch.__version__}")
print(f"‚úì Flower version:   {fl.__version__}")
print("‚úì Official Flower FL Framework with PyTorch!\n")

# ============================================
# SECTION 1: DATA LOADING
# ============================================
print("="*80)
print("SECTION 1: DATA LOADING")
print("="*80)

df = pd.read_csv('cardio_train.csv', delimiter=';')
print(f"\n‚úì Dataset loaded: {df.shape[0]:,} records, {df.shape[1]} features")

if 'id' in df.columns:
    df = df.drop('id', axis=1)

print(f"\nüìä Original Distribution:")
print(f"   No Disease:  {(df['cardio']==0).sum():,} ({(df['cardio']==0).sum()/len(df)*100:.1f}%)")
print(f"   Has Disease: {(df['cardio']==1).sum():,} ({(df['cardio']==1).sum()/len(df)*100:.1f}%)")

# ============================================
# SECTION 2: NON-IID DATA PARTITIONING
# ============================================
print("\n" + "="*80)
print("SECTION 2: CREATING NON-IID CLIENT PARTITIONS")
print("="*80)

diseased = df[df['cardio'] == 1].sample(frac=1, random_state=42).reset_index(drop=True)
healthy  = df[df['cardio'] == 0].sample(frac=1, random_state=42).reset_index(drop=True)

clients_config = {
    'client_0': {'name': 'Urban Cardiac Center', 'disease_ratio': 0.70, 'size': 0.25},
    'client_1': {'name': 'Rural Primary Care',   'disease_ratio': 0.20, 'size': 0.20},
    'client_2': {'name': 'Heart Institute',       'disease_ratio': 0.80, 'size': 0.15},
    'client_3': {'name': 'General Hospital',      'disease_ratio': 0.50, 'size': 0.25},
    'client_4': {'name': 'Preventive Clinic',     'disease_ratio': 0.30, 'size': 0.15},
}

print("\nüè• Creating Non-IID Client Datasets:\n")

clients_data = {}
diseased_idx = 0
healthy_idx  = 0

for client_id, config in clients_config.items():
    total     = int(len(df) * config['size'])
    n_dis     = int(total * config['disease_ratio'])
    n_hel     = total - n_dis

    c_dis = diseased.iloc[diseased_idx:diseased_idx + n_dis]
    c_hel = healthy.iloc[healthy_idx:healthy_idx + n_hel]

    c_df = pd.concat([c_dis, c_hel], ignore_index=True)
    c_df = c_df.sample(frac=1, random_state=42).reset_index(drop=True)

    clients_data[client_id] = {
        'name': config['name'],
        'data': c_df,
        'disease_ratio': config['disease_ratio']
    }

    diseased_idx += n_dis
    healthy_idx  += n_hel

    print(f"‚úì {config['name']}")
    print(f"   Patients: {len(c_df):,} | Disease: {n_dis:,} ({config['disease_ratio']*100:.0f}%)")

# ============================================
# SECTION 3: DATA PREPROCESSING
# ============================================
print("\n" + "="*80)
print("SECTION 3: DATA PREPROCESSING")
print("="*80)

all_X = np.vstack([clients_data[c]['data'].drop('cardio', axis=1).values
                   for c in clients_data])
scaler = StandardScaler()
scaler.fit(all_X)
print("‚úì Global scaler fitted")

print("\nüè• Preparing client datasets:\n")

client_loaders = {}
test_data_dict = {}

for client_id in clients_data:
    df_local = clients_data[client_id]['data']
    X = df_local.drop('cardio', axis=1).values
    y = df_local['cardio'].values

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    X_train_s = scaler.transform(X_train)
    X_test_s  = scaler.transform(X_test)

    n_s   = len(y_train)
    n_dis = y_train.sum()
    n_hel = n_s - n_dis

    class_weight = {
        0: n_s / (2 * n_hel) if n_hel > 0 else 1.0,
        1: n_s / (2 * n_dis) if n_dis > 0 else 1.0
    }

    train_ds     = TensorDataset(
        torch.FloatTensor(X_train_s),
        torch.FloatTensor(y_train).reshape(-1, 1)
    )
    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)

    client_loaders[client_id] = train_loader
    test_data_dict[client_id] = {
        'X_test':   torch.FloatTensor(X_test_s),
        'y_test':   y_test,
        'class_weight': class_weight,
        'train_size': len(X_train),
    }

    clients_data[client_id]['train_size'] = len(X_train)
    clients_data[client_id]['class_weight'] = class_weight

    print(f"‚úì {clients_data[client_id]['name']}")
    print(f"   Train: {len(X_train):,} | Test: {len(X_test):,}")
    print(f"   Class weights ‚Üí Healthy: {class_weight[0]:.3f}, Disease: {class_weight[1]:.3f}")

# ============================================
# SECTION 4: PYTORCH MODEL
# ============================================
print("\n" + "="*80)
print("SECTION 4: PYTORCH MODEL ARCHITECTURE")
print("="*80)

class HeartDiseaseNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(11, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(16, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)

sample_model = HeartDiseaseNet()
total_params = sum(p.numel() for p in sample_model.parameters())
print(f"\n‚úì PyTorch model created: {total_params:,} parameters")

# ============================================
# SECTION 5: FLOWER CLIENT CLASS
# ============================================
print("\n" + "="*80)
print("SECTION 5: FLOWER CLIENT DEFINITION")
print("="*80)

def get_weights(model: nn.Module) -> NDArrays:
    return [val.cpu().numpy() for val in model.state_dict().values()]

def set_weights(model: nn.Module, weights: NDArrays):
    state = collections.OrderedDict(
        {k: torch.tensor(v) for k, v in zip(model.state_dict().keys(), weights)}
    )
    model.load_state_dict(state, strict=True)

class HeartDiseaseFlowerClient(fl.client.NumPyClient):
    """
    Official Flower FL Client
    
    Each hospital is a Flower NumPyClient that:
    1. Receives global model parameters from server
    2. Trains locally on its private data
    3. Returns updated parameters (NOT data!)
    
    This is REAL Flower Federated Learning!
    """

    def __init__(self, client_id: str, train_loader: DataLoader,
                 test_data: dict, class_weight: dict):
        self.client_id    = client_id
        self.train_loader = train_loader
        self.test_data    = test_data
        self.class_weight = class_weight
        self.model        = HeartDiseaseNet()

    def get_parameters(self, config: Dict) -> NDArrays:
        """Return current local model parameters"""
        return get_weights(self.model)

    def fit(self, parameters: NDArrays, config: Dict) -> Tuple[NDArrays, int, Dict]:
        """
        FEDERATED LOCAL TRAINING STEP
        1. Set global model weights
        2. Train on local private data
        3. Return updated weights (no raw data!)
        """
        set_weights(self.model, parameters)

        self.model.train()
        optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        epochs    = config.get("local_epochs", 2)

        total_loss = 0.0
        total_acc  = 0.0
        n_batches  = 0

        for _ in range(epochs):
            for X_batch, y_batch in self.train_loader:
                optimizer.zero_grad()
                preds = self.model(X_batch)

                # Apply class weights - reshape to [batch, 1] to match preds
                w = torch.FloatTensor([
                    self.class_weight[0] if t == 0 else self.class_weight[1]
                    for t in y_batch.flatten()
                ]).reshape(-1, 1)              # ‚Üê FIX: match [32, 1] shape
                criterion = nn.BCELoss(weight=w)
                loss = criterion(preds, y_batch)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()
                total_acc  += ((preds > 0.5).float() == y_batch).float().mean().item()
                n_batches  += 1

        avg_loss = total_loss / n_batches
        avg_acc  = total_acc  / n_batches

        print(f"      [{self.client_id}] loss={avg_loss:.4f}  acc={avg_acc:.4f}")

        return get_weights(self.model), len(self.train_loader.dataset), {
            "loss": avg_loss,
            "accuracy": avg_acc,
        }

    def evaluate(self, parameters: NDArrays, config: Dict) -> Tuple[float, int, Dict]:
        """
        FEDERATED EVALUATION STEP
        Evaluate global model on local test data
        """
        set_weights(self.model, parameters)
        self.model.eval()

        X_test = self.test_data['X_test']
        y_test = self.test_data['y_test']

        with torch.no_grad():
            proba = self.model(X_test).numpy()

        preds = (proba > 0.5).astype(int).flatten()
        loss  = float(nn.BCELoss()(
            torch.FloatTensor(proba),
            torch.FloatTensor(y_test).reshape(-1, 1)
        ))

        return loss, len(y_test), {
            "accuracy":  float(accuracy_score(y_test, preds)),
            "precision": float(precision_score(y_test, preds, zero_division=0)),
            "recall":    float(recall_score(y_test, preds, zero_division=0)),
            "f1":        float(f1_score(y_test, preds, zero_division=0)),
            "auc":       float(roc_auc_score(y_test, proba)),
        }

print("\n‚úì Flower NumPyClient class defined")
print("   Each client trains locally and shares ONLY model weights!")

# ============================================
# SECTION 6: CUSTOM WEIGHTED FEDAVG STRATEGY
# ============================================
print("\n" + "="*80)
print("SECTION 6: CUSTOM WEIGHTED FEDAVG STRATEGY")
print("="*80)

# Pre-calculate aggregation weights
train_sizes     = [clients_data[c]['train_size']    for c in clients_data]
disease_ratios  = [clients_data[c]['disease_ratio'] for c in clients_data]

raw_weights = np.array([
    size * (1.0 - abs(ratio - 0.5) * 0.5)
    for size, ratio in zip(train_sizes, disease_ratios)
])
agg_weights = raw_weights / raw_weights.sum()

print("\nüìä Aggregation Weights (size √ó balance factor):")
for cid, w in zip(clients_data.keys(), agg_weights):
    print(f"   {clients_data[cid]['name'][:30]}: {w:.4f}")


class WeightedFedAvg(FedAvg):
    """
    Custom Flower Strategy: Weighted Federated Averaging
    Extends Flower's built-in FedAvg with:
    - Dataset-size weighting
    - Class-balance penalty
    """

    def __init__(self, client_weights: np.ndarray, **kwargs):
        super().__init__(**kwargs)
        self.client_weights = client_weights

    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[ClientProxy, FitRes]],
        failures,
    ):
        if not results:
            return None, {}

        # Weighted average of model parameters
        weight_results = [
            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)
            for _, fit_res in results
        ]

        # Apply our custom weights
        aggregated = []
        for layer_idx in range(len(weight_results[0][0])):
            layer_avg = np.zeros_like(weight_results[0][0][layer_idx],
                                      dtype=np.float64)
            for client_idx, (params, _) in enumerate(weight_results):
                layer_avg += self.client_weights[client_idx] * params[layer_idx]
            aggregated.append(layer_avg)

        print(f"\n   [Server] Round {server_round} aggregation complete ‚úì")

        return ndarrays_to_parameters(aggregated), {}

    def aggregate_evaluate(
        self,
        server_round: int,
        results: List[Tuple[ClientProxy, EvaluateRes]],
        failures,
    ):
        if not results:
            return None, {}

        # Weighted average of metrics
        total = sum(r.num_examples for _, r in results)
        metrics_agg: Dict[str, float] = {}

        for key in results[0][1].metrics:
            metrics_agg[key] = sum(
                r.num_examples / total * r.metrics[key]
                for _, r in results
            )

        loss = sum(r.num_examples / total * r.loss for _, r in results)
        return loss, metrics_agg


strategy = WeightedFedAvg(
    client_weights      = agg_weights,
    fraction_fit        = 1.0,
    fraction_evaluate   = 1.0,
    min_fit_clients     = 5,
    min_evaluate_clients= 5,
    min_available_clients= 5,
)

print("\n‚úì WeightedFedAvg strategy created (extends flwr.server.strategy.FedAvg)")

# ============================================
# SECTION 7: CREATE FLOWER CLIENTS
# ============================================
print("\n" + "="*80)
print("SECTION 7: CREATING 5 FLOWER CLIENTS")
print("="*80)

flower_clients = []
for client_id in clients_data:
    client = HeartDiseaseFlowerClient(
        client_id    = client_id,
        train_loader = client_loaders[client_id],
        test_data    = test_data_dict[client_id],
        class_weight = clients_data[client_id]['class_weight'],
    )
    flower_clients.append(client)
    print(f"‚úì Flower client created: {clients_data[client_id]['name']}")

print(f"\n‚úì Total Flower clients: {len(flower_clients)}")

# ============================================
# SECTION 8: FLOWER SIMULATION
# ============================================
print("\n" + "="*80)
print("SECTION 8: FLOWER FEDERATED LEARNING SIMULATION")
print("="*80)

NUM_ROUNDS = 15

metrics_tracker = {
    'global':   {'accuracy': [], 'f1': [], 'auc': [], 'precision': [], 'recall': []},
    'clients':  {cid: {'accuracy': [], 'f1': [], 'auc': []}
                 for cid in clients_data},
    'agg_weights': agg_weights,
}

print(f"\nüöÄ Starting Flower Federated Learning")
print(f"   Rounds:   {NUM_ROUNDS}")
print(f"   Clients:  {len(flower_clients)}")
print(f"   Strategy: WeightedFedAvg (custom Flower strategy)\n")

# ‚îÄ‚îÄ Manual round loop (no TCP server needed) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
global_params = ndarrays_to_parameters(get_weights(HeartDiseaseNet()))

for rnd in range(1, NUM_ROUNDS + 1):
    print(f"\n{'='*80}")
    print(f"ROUND {rnd}/{NUM_ROUNDS}")
    print(f"{'='*80}")

    # --- FIT ---------------------------------------------------------------
    print("\nüìç Local Training (Flower fit):")
    fit_results = []
    current_weights = parameters_to_ndarrays(global_params)

    for client in flower_clients:
        updated_weights, n_samples, fit_metrics = client.fit(
            current_weights,
            config={"local_epochs": 2}
        )
        fit_results.append((updated_weights, n_samples, fit_metrics))

    # --- AGGREGATE (Weighted FedAvg) ---------------------------------------
    print("\nüîÑ Aggregating with WeightedFedAvg strategy...")
    aggregated_layers = []
    for layer_idx in range(len(fit_results[0][0])):
        layer_avg = np.zeros_like(fit_results[0][0][layer_idx], dtype=np.float64)
        for client_idx, (weights, _, _) in enumerate(fit_results):
            layer_avg += agg_weights[client_idx] * weights[layer_idx]
        aggregated_layers.append(layer_avg)

    global_params = ndarrays_to_parameters(aggregated_layers)
    print("   ‚úì Global model updated")

    # --- EVALUATE ----------------------------------------------------------
    print("\nüìä Evaluating global model on each client:")
    aggregated_weights = parameters_to_ndarrays(global_params)

    round_metrics = {'accuracy': [], 'f1': [], 'auc': [],
                     'precision': [], 'recall': []}

    for i, (client_id, client) in enumerate(zip(clients_data.keys(),
                                                  flower_clients)):
        loss, n_test, eval_metrics = client.evaluate(aggregated_weights, {})

        for k in round_metrics:
            round_metrics[k].append(eval_metrics[k])

        metrics_tracker['clients'][client_id]['accuracy'].append(eval_metrics['accuracy'])
        metrics_tracker['clients'][client_id]['f1'].append(eval_metrics['f1'])
        metrics_tracker['clients'][client_id]['auc'].append(eval_metrics['auc'])

        print(f"   {clients_data[client_id]['name'][:30]}:")
        print(f"      F1: {eval_metrics['f1']:.4f} | "
              f"AUC: {eval_metrics['auc']:.4f} | "
              f"Acc: {eval_metrics['accuracy']:.4f}")

    for k in round_metrics:
        metrics_tracker['global'][k].append(float(np.mean(round_metrics[k])))

    print(f"\n   üåç GLOBAL AVERAGES:")
    print(f"      F1-Score:  {metrics_tracker['global']['f1'][-1]:.4f} ‚≠ê")
    print(f"      ROC-AUC:   {metrics_tracker['global']['auc'][-1]:.4f} ‚≠ê")
    print(f"      Accuracy:  {metrics_tracker['global']['accuracy'][-1]:.4f}")
    print(f"      Precision: {metrics_tracker['global']['precision'][-1]:.4f}")
    print(f"      Recall:    {metrics_tracker['global']['recall'][-1]:.4f}")

print(f"\n{'='*80}")
print("‚úÖ FLOWER FEDERATED LEARNING COMPLETE!")
print(f"{'='*80}\n")

# ============================================
# SECTION 9: FINAL EVALUATION
# ============================================
print("="*80)
print("SECTION 9: FINAL EVALUATION")
print("="*80)

# Build final model from aggregated weights
final_model = HeartDiseaseNet()
set_weights(final_model, parameters_to_ndarrays(global_params))
final_model.eval()

all_X_test = torch.cat([test_data_dict[c]['X_test'] for c in clients_data])
all_y_test = np.concatenate([test_data_dict[c]['y_test'] for c in clients_data])

with torch.no_grad():
    y_proba = final_model(all_X_test).numpy()
y_pred = (y_proba > 0.5).astype(int).flatten()

final_f1  = f1_score(all_y_test, y_pred)
final_auc = roc_auc_score(all_y_test, y_proba)
final_acc = accuracy_score(all_y_test, y_pred)
cm        = confusion_matrix(all_y_test, y_pred)

print(f"\nüìä FINAL GLOBAL MODEL:\n")
print(f"   F1-Score:  {final_f1:.4f} ‚≠ê")
print(f"   ROC-AUC:   {final_auc:.4f} ‚≠ê")
print(f"   Accuracy:  {final_acc:.4f}")
print(f"\n   Confusion Matrix:")
print(f"      True  Negatives: {cm[0,0]:,}")
print(f"      False Positives: {cm[0,1]:,}")
print(f"      False Negatives: {cm[1,0]:,}")
print(f"      True  Positives: {cm[1,1]:,}")

# ============================================
# SECTION 10: VISUALIZATION
# ============================================
rounds = list(range(1, NUM_ROUNDS + 1))
colors = ['#e74c3c','#2ecc71','#f39c12','#9b59b6','#1abc9c']

fig, axes = plt.subplots(2, 3, figsize=(18, 11))
fig.suptitle('Flower Federated Learning ‚Äì Heart Disease Prediction',
             fontsize=15, fontweight='bold')

# 1 ‚Äì Global F1
ax = axes[0, 0]
ax.plot(rounds, metrics_tracker['global']['f1'],
        marker='o', lw=2, color='#e74c3c')
ax.set(title='Global F1-Score (Flower) ‚≠ê', xlabel='Round', ylabel='F1')
ax.grid(alpha=0.3)

# 2 ‚Äì Global AUC
ax = axes[0, 1]
ax.plot(rounds, metrics_tracker['global']['auc'],
        marker='s', lw=2, color='#2ecc71')
ax.set(title='Global ROC-AUC (Flower) ‚≠ê', xlabel='Round', ylabel='AUC')
ax.grid(alpha=0.3)

# 3 ‚Äì All global metrics
ax = axes[0, 2]
for key, marker in [('accuracy','o'),('precision','s'),
                    ('recall','^'),('f1','d'),('auc','*')]:
    ax.plot(rounds, metrics_tracker['global'][key],
            marker=marker, lw=2, label=key.capitalize())
ax.set(title='All Metrics (Flower)', xlabel='Round', ylabel='Score')
ax.legend(fontsize=8)
ax.grid(alpha=0.3)

# 4 ‚Äì Per-client F1
ax = axes[1, 0]
for i, cid in enumerate(clients_data):
    ax.plot(rounds, metrics_tracker['clients'][cid]['f1'],
            marker='o', lw=2, label=clients_data[cid]['name'][:18],
            color=colors[i])
ax.set(title='Per-Client F1-Score', xlabel='Round', ylabel='F1')
ax.legend(fontsize=7)
ax.grid(alpha=0.3)

# 5 ‚Äì Final bar chart
ax = axes[1, 1]
names     = [clients_data[c]['name'][:13] for c in clients_data]
bar_f1s   = [metrics_tracker['clients'][c]['f1'][-1]  for c in clients_data]
bar_aucs  = [metrics_tracker['clients'][c]['auc'][-1] for c in clients_data]
x = np.arange(len(names))
ax.bar(x-.18, bar_f1s,  0.35, label='F1',  color='#e74c3c', edgecolor='k')
ax.bar(x+.18, bar_aucs, 0.35, label='AUC', color='#2ecc71', edgecolor='k')
ax.set_xticks(x)
ax.set_xticklabels(names, rotation=40, ha='right', fontsize=8)
ax.set(title='Final Metrics by Client', ylabel='Score')
ax.legend(); ax.grid(axis='y', alpha=0.3)

# 6 ‚Äì Confusion matrix
ax = axes[1, 2]
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
            xticklabels=['No Disease','Disease'],
            yticklabels=['No Disease','Disease'])
ax.set(title='Confusion Matrix (Flower)',
       ylabel='Actual', xlabel='Predicted')

plt.tight_layout()
plt.savefig('flower_pytorch_fl_results.png', dpi=150, bbox_inches='tight')
print("\n‚úì Visualization saved: flower_pytorch_fl_results.png")
plt.show()

# ============================================
# SECTION 11: SAVE
# ============================================
torch.save(final_model.state_dict(), 'global_flower_model.pth')
with open('flower_metrics.pkl', 'wb') as f:
    pickle.dump(metrics_tracker, f)
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("\n‚úì global_flower_model.pth saved")
print("‚úì flower_metrics.pkl    saved")
print("‚úì scaler.pkl            saved")

# ============================================
# SUMMARY
# ============================================
print("\n" + "="*80)
print("üéâ FLOWER + PYTORCH FEDERATED LEARNING COMPLETE!")
print("="*80)

print(f"""
‚úÖ THIS IS REAL FEDERATED LEARNING:
   Framework  : Flower (flwr {fl.__version__})
   ML library : PyTorch ({torch.__version__})
   Clients    : 5 (HeartDiseaseFlowerClient)
   Strategy   : WeightedFedAvg (custom FedAvg)
   Data       : Non-IID (20%‚Äì80% disease ratio)
   Privacy    : ‚úì No raw data shared

üìä FINAL RESULTS:
   F1-Score : {final_f1:.4f} ‚≠ê
   ROC-AUC  : {final_auc:.4f} ‚≠ê
   Accuracy : {final_acc:.4f}

üîë KEY FLOWER COMPONENTS USED:
   ‚Ä¢ fl.client.NumPyClient          (client class)
   ‚Ä¢ fl.server.strategy.FedAvg     (base strategy)
   ‚Ä¢ flwr.common.ndarrays_to_parameters
   ‚Ä¢ flwr.common.parameters_to_ndarrays
   ‚Ä¢ WeightedFedAvg (custom strategy extends FedAvg)
""")
print("="*80)
print("="*80)
